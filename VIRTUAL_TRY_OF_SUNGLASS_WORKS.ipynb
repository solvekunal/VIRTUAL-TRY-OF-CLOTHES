{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02161e68-c6a4-4785-880d-c8b614b86a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ce2319-5136-46df-bced-6c5666e5e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe Face Mesh for face landmarks detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "292e779b-bef7-4326-90d8-2b09cc3e5d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the virtual glasses image with transparent background (PNG format)\n",
    "glasses = cv2.imread(r'E:\\jupyter_notebook\\Pictures\\tshirt1.png', cv2.IMREAD_UNCHANGED)\n",
    "glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760f1a53-9841-4b5c-a2e1-4cf2599fdb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('glass',glasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9d088-b097-4f63-8cb9-289563106c65",
   "metadata": {},
   "source": [
    "# VIRTUAL TRY ON MODEL using MEDIAPIPE(pose estimation). This works perfectly fine even if your face goes out of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ad7264-0611-4e81-9815-68696a7cc5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the glasses image was loaded correctly\n",
    "if glasses is None:\n",
    "    raise FileNotFoundError(\"Glasses image file not found. Please check the file path.\")\n",
    "\n",
    "# Function to overlay the glasses on the face\n",
    "def overlay_glasses(frame, face_landmarks, glasses):\n",
    "    # Get landmarks for the eyes\n",
    "    left_eye = face_landmarks.landmark[33]  # Left eye landmark\n",
    "    right_eye = face_landmarks.landmark[263]  # Right eye landmark\n",
    "\n",
    "    # Convert normalized coordinates to pixel values\n",
    "    h, w, _ = frame.shape\n",
    "    left_eye = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "    right_eye = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "    # Calculate the width of the glasses based on eye distance\n",
    "    glasses_width = int(((right_eye[0] - left_eye[0]) ** 2 + (right_eye[1] - left_eye[1]) ** 2) ** 0.5 * 2)\n",
    "\n",
    "    # Resize the glasses to fit the face\n",
    "    glasses_resized = cv2.resize(glasses, (glasses_width, int(glasses.shape[0] * (glasses_width / glasses.shape[1]))))\n",
    "\n",
    "    # Calculate the position to place the glasses\n",
    "    top_left = (left_eye[0] - glasses_resized.shape[1] // 4, left_eye[1] - glasses_resized.shape[0] // 2)\n",
    "\n",
    "    # Ensure the overlay does not exceed the frame boundaries\n",
    "    for i in range(glasses_resized.shape[0]):\n",
    "        for j in range(glasses_resized.shape[1]):\n",
    "            # Calculate the pixel position in the frame\n",
    "            y_pos = top_left[1] + i\n",
    "            x_pos = top_left[0] + j\n",
    "\n",
    "            # Check if the position is within the frame boundaries\n",
    "            if 0 <= x_pos < w and 0 <= y_pos < h and glasses_resized[i, j, 3] > 0:\n",
    "                frame[y_pos, x_pos] = glasses_resized[i, j, :3]\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for Mediapipe processing\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get face landmarks\n",
    "    result = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # If landmarks are detected, overlay the glasses\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            frame = overlay_glasses(frame, face_landmarks, glasses)\n",
    "\n",
    "    # Display the result\n",
    "    cv2.imshow('Virtual Try-On', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6c9e8-5986-428d-842c-11a52f630f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177d32d-4e3a-4ef4-8ee8-9e83d34de88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8582ce6-b037-4cc9-8ff5-1298127ff38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef907585-d905-452f-b7b2-f12238b64036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a2400-e0b8-4da7-8e28-74331c29a23a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391cefc-82aa-4404-b563-07d3e464bc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d4bbde8-0e84-40f9-ba8d-e88c2824b240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video E:\\jupyter_notebook\\Pictures\\sunglass_output_with_audio.mp4.\n",
      "Moviepy - Writing video E:\\jupyter_notebook\\Pictures\\sunglass_output_with_audio.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready E:\\jupyter_notebook\\Pictures\\sunglass_output_with_audio.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Initialize Mediapipe Face Mesh for face landmarks detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Load the virtual glasses image with transparent background (PNG format)\n",
    "glasses = cv2.imread(r'E:\\jupyter_notebook\\Pictures\\sunglass1.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Check if the glasses image was loaded correctly\n",
    "if glasses is None:\n",
    "    raise FileNotFoundError(\"Glasses image file not found. Please check the file path.\")\n",
    "\n",
    "# Function to overlay the glasses on the face with tilt adjustment\n",
    "def overlay_glasses(frame, face_landmarks, glasses):\n",
    "    # Get landmarks for the eyes\n",
    "    left_eye = face_landmarks.landmark[33]  # Left eye landmark\n",
    "    right_eye = face_landmarks.landmark[263]  # Right eye landmark\n",
    "\n",
    "    # Convert normalized coordinates to pixel values\n",
    "    h, w, _ = frame.shape\n",
    "    left_eye = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "    right_eye = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "    # Calculate the width of the glasses based on eye distance\n",
    "    eye_distance = np.sqrt((right_eye[0] - left_eye[0]) ** 2 + (right_eye[1] - left_eye[1]) ** 2)\n",
    "    glasses_width = int(eye_distance * 1.2)  # Adding some extra width for a better fit\n",
    "    glasses_height = int(glasses.shape[0] * (glasses_width / glasses.shape[1]))\n",
    "\n",
    "    # Resize the glasses to fit the face\n",
    "    glasses_resized = cv2.resize(glasses, (glasses_width, glasses_height))\n",
    "\n",
    "    # Calculate the angle of rotation for the glasses\n",
    "    dx = right_eye[0] - left_eye[0]\n",
    "    dy = right_eye[1] - left_eye[1]\n",
    "    angle = np.degrees(np.arctan2(dy, dx))  # Correct angle calculation\n",
    "\n",
    "    # Calculate the center point for rotation (between the eyes)\n",
    "    center = (int((left_eye[0] + right_eye[0]) / 2), int((left_eye[1] + right_eye[1]) / 2))\n",
    "\n",
    "    # Create the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Rotate the glasses image\n",
    "    glasses_rotated = cv2.warpAffine(glasses_resized, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0, 0))\n",
    "\n",
    "    # Calculate the position to place the glasses\n",
    "    top_left = (int(center[0] - glasses_rotated.shape[1] / 2), int(center[1] - glasses_rotated.shape[0] / 2))\n",
    "\n",
    "    # Ensure the overlay does not exceed the frame boundaries\n",
    "    for i in range(glasses_rotated.shape[0]):\n",
    "        for j in range(glasses_rotated.shape[1]):\n",
    "            # Calculate the pixel position in the frame\n",
    "            y_pos = top_left[1] + i\n",
    "            x_pos = top_left[0] + j\n",
    "\n",
    "            # Check if the position is within the frame boundaries\n",
    "            if 0 <= x_pos < w and 0 <= y_pos < h and glasses_rotated[i, j, 3] > 0:\n",
    "                frame[y_pos, x_pos] = glasses_rotated[i, j, :3]\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Initialize video capture from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer to save the output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(r'E:\\jupyter_notebook\\Pictures\\sunglass_output_virtual_try.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for Mediapipe processing\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Get face landmarks\n",
    "    result = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # If landmarks are detected, overlay the glasses\n",
    "    if result.multi_face_landmarks:\n",
    "        for face_landmarks in result.multi_face_landmarks:\n",
    "            frame = overlay_glasses(frame, face_landmarks, glasses)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the result in real-time\n",
    "    cv2.imshow('Virtual Try-On', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Add the original audio from the live feed (if available) to the saved video\n",
    "try:\n",
    "    # Load the saved video\n",
    "    processed_video = VideoFileClip(r'E:\\jupyter_notebook\\Pictures\\sunglass_output_virtual_try.mp4')\n",
    "\n",
    "    # Add the original audio (captured by the webcam) if available\n",
    "    final_video = processed_video.set_audio(processed_video.audio)\n",
    "    final_video.write_videofile(r'E:\\jupyter_notebook\\Pictures\\sunglass_output_with_audio.mp4', codec=\"libx264\")\n",
    "except Exception as e:\n",
    "    print(f\"Audio could not be added to the video: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
